{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota para antes de leer este documento:<br>\n",
    "<b><i> 1. El paquete dst contiene toda la implementacion de las ideas aqui expuestas. EL notebook 2.Experimentos incluye implementaciones para distintas configuraciones. En el presente documento se expondra codigo de manera ilustrativa, sin embargo, el paquete es el encargado de relizar los procedimientos aqui expuestos. Para ver la implementacion puede dirigirse al codigo fuente, al enlace a colab o al notebook de experimentos. </i></b>\n",
    "<br><br>\n",
    "<b><i> 2. La implementacion que se realizo se basa en el documento  <a href= \"https://www.cvfoundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\">Image Style Transfer Using Convolutional Neural Networks</a>, en el blog de tensorflow y en el este blog</i></b>\n",
    "<br><br>\n",
    "<b><i> 3. La implementacion esta escrita en python3 usando tensorflow y keras</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"width: 100%;text-align:center;\"> Aprendizaje profundo para la transferencia de estilo </h1>\n",
    "<p style=\"width: 100%;text-align:center;\">  Universidad de Antioquia <br> Angelower Santana Velasquez <br> Martin Elias Quintero  Osorio</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"width: 100%;text-align:center;\">Motivacion</h2>\n",
    "<p>El deep learning (<b>aprendizaje profundo</b>) es un campo especifico del aprendizaje automatico(<b>machine learning</b>) y en consecuencia de la inteligencia artificial(<b>AI</b>), el cual,  ha demostrado un avance exponencial los ultimos anos. El Deep Learnig ha sorprendido por sus increibles resultados en multiples areas para solicionar distintos tipos de problema. Especificamente el deep learning gira en torno al estudio de modelos basados en redes neuronales artificiales, sus funciones de perdida, la capacidad de distintos tipos de optimizacion, estrategias para evitar el sobreajuste, el diseno de  arquitecturas de redes neuronales enfocadas a cumplir objetivos desde distintos enfoques de  aprendizaje, ente muchas otras estrategias que son de gran importancia dentro del Machine Learning.\n",
    "Podemos encontrar varias ramas del Deep Learning como el  procesamiento de lenguaje natural(NLP) y la vision por computadora(Computer Vision -CV),siendo esta ultima materia de estudio desde hace mas de una decada teniendo avances sorprendentes. Hoy dia podemos ver el aprovechamiento de la vision computacional en aplicaciones implementadas en  aeropuertos, automoviles, en la indutria y, no muy alejado, en nuestros telefonos inteligentes. Dentro del <b>Deep Learning</b> existe un tipo de red neuronal capaz de emular, segun algunas personas, el comportamiento biologico que ocurre en los seres humanos en el proceso de \"vision\", las redes neuronales convolucionales (<b>CNN</b>), llamadas asi por realizar operaciones de convolucion dentro del proceso de enternamiento, operador bastante utilizado en el procesamiento de senales. Y son este tipo de redes neuronales casi la opcion por defecto para tratar problemas de vision computacional.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La capacidad de computo que disponemos actualmente ha permitido que se realicen multiples experimentos y se desarrollen ideas sorprendestes para el ojo comun. Sistemas que controlan automoviles, aplicaciones que determinan cierto tipo de enfermedades en plantas, filtros y aplicacion de diferentes \"mascaras\" en imagenes en tiempo real (por ejemplo instagram y snapchat), deteccion de enfermedades bajo la deteccion de patrones (por ejemplo la retinopatia diabetica) y  la clasificacion de objetos son ejemplos de la capacidad que pueden lograr sistemas basados en redes neuronales convolucionales. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Una cita de uno de los artistas mas importantes del siglo XX, Pablo Piccaso, dice : “La pintura es más fuerte que yo, siempre consigue que haga lo que ella quiere”. El presente infome explora una aplicacicon bastante ingeniosa para generar \"arte\" apartir de tecnicas de Deep Learning con redes neuronales convolucionales. Que de forma similar a la frase de Piccaso, sera nuestro modelo el encargado de generar una imagen a su antojo a partir de dos fuentes de datos: Una imagen de conteneido y otra de estilo. Ahora, podrias imaginar como Vincent van Gogh habria pintado a Medellin? </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"../images/medellin_van.png\" alt=\"Drawing\" style=\"width: 100px;\"> <p style=\"width: 100%;text-align:center;\"><b><i>imagen 1 </i></b> <br><b>The starry night in Medellín</b> <br> Imagen contenido: Fotografia del centro de Medellín<br> Imagen estilo: The Starry Night - Vincent van Gogh  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"width: 100%;text-align:center;\">Contenido y estilo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cubismo fue un movimiento artistico donde se queria representar elementos de la cotidianidad en composiciones  de formas geometricas bien definidas. Es decir, tomar un elemento, capturar su escencia y plasmarla en cubos, triangulos y rectangulos. De esa manera definimos el contenido de una imagen como la escencia que tiene dejando a un lado elementos como el color y la textura. Por otro lado, cuando hablemos de estilo nos referimos a la forma, los colores, sombras y otros matices que no sean la escencia. De hecho, la tranferencia de estilo  busca  tomar la escencia y plasmar en ella la forma y colores de otra imagen. Por ejemplo, en la <b><i>imagen 1 </i></b>, el contenido es la fotografia de medellin <b><i>imagen 2 lado derecho superior</i></b> y el estilo es la famosa pintura de Vicent Van Gogh : The starry night. <b><i>imagen 2 lado derecho inferior </i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/Thestarrynightinmedellin.png\">\n",
    "<p style=\"width: 100%;text-align:center;\"><b><i>imagen 2 </i></b> <br><b>The starry night in Medellín (Contenido, estilo y resultado)</b> <br> Lado izquierdo: Resultado de Deep Transfer Style <br> Lado Derecho parte superior: Contenido<br>Lado Derecho parte inferior: Estilo</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"width: 100%;text-align:center;\">Deep Transfer Style</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea detras de la tecnica de transferencia de estilo es la representacion interna que producen las redes neuronales convolucionales una vez entrenadas. Dichas redes estan conformadas por capas que tienen por objetivo propositos especificos: Algunas sirven como mapa de activacion que nos indica que tan sensible es una imagen a un patron o filtro. En otras palabras, si aplicamos un fitro que detecte bordes y formas cuadradas a una imagen de un televisor probablemente la forma del televisor se activara con dicho filtros. Dentro del proceso de entrenamiento la red aprende a detectar estas formas que inician con figuras muy basicas hasta evolucionar a detalles y figuras compuestas, aunque no por esto se llaman redes convolucionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la <b><i>imagen 3</i></b> se puede observar una arquitectura de red bastante famosa, <b><i>VGG16</i></b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/vgg16.png\">\n",
    "<p style=\"width: 100%;text-align:center;\"><b><i>imagen 3 </i></b> <br><b>How convolutional neural networks see the world</b> <br> Fuente: <a href=\"https://neurohive.io/en/popular-networks/vgg16/\" >Blog</a></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>VGG16</i></b> cuenta con 5 bloques internos compuestios por capas de convolucion y de pooling(este tipo de capas reduce el volumen de los mapas de caracteristicas, en la imagen 3 en rojo).Cada bloque cuenta con cierta cantidad de capas de convolucion, una notacion para determinar las capas es especificar el numero de bloque y la posicion que esta tiene dentro del arreglo.Por ejemplo la capa convolucional dos del bloqe uno se representaria como : <b><i>Conv2_1</i></b>, mientras la capa convolucional tres en el bloque cuatro sera : <b><i>Conv4_3</i></b>. <br> Como se menciono anteriormente en el proceso de entrenamiento la red aprende multiples filtros, la siguiente pregunta que debemos realizar es : Que esta viendo la red realmente?, Que es lo que esta detectando esos filtros? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La <b><i>imagen 4</i></b> nos da una respuesta a dichas preguntas. Podemos observar que luego del entrenamiento conv1_1 es capaz de detectar ciertos colores y un par de texturas. Mientras tanto <b><i>conv2_1</i></b> parece ser el resultado de combinar las texturas y colores de <b><i>conv1_1</i></b>, recordemos que en medio de estas capas y de las siguientes que mecionaremos existen otras capas y operaciones que tendran combinaciones de este tipo.<br>\n",
    "Pasando a <b><i>conv3_1</i></b>, podemos hacer dos obseraciones, la primera es que los colores se ven mucho mas granulados que en las dos capas anteriormente estudiadas y empieza a aparecer forma mas definidas como lineas diagonales curvas o puntos bien detallados. <br>\n",
    "<b><i>Conv4_1</i></b> nos muetra un salto enorme respecto a <b><i>conv3_1</i></b>. Podemos identificar con facilidad formas mas especificas, agrupaciones de lineas, circulos y combinacion de colores que se organizan de forma no uniforme.<br>\n",
    "Finalmente, <b><i>conv5_1</i></b>, muestra filtros que ya saben detectar formas bien definidas, mas delineadas, llevando las imagenes a una representacion mas abstracta a medida que avanza por las diferentes capas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/vgg16_filters_overview.jpg\">\n",
    "<p style=\"width: 100%;text-align:center;\"><b><i>imagen 4 </i></b> <br><b>How convolutional neural networks see the world</b> <br> Fuente: <a href=\"https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\" >Blog de Keras por Francois Chollet</a></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El analisis anterior es el pilar de la tecnica de transferencia de estilo presentada por Leon A. Gatys en el articulo <a href= \"https://www.cvfoundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf\">Image Style Transfer Using Convolutional Neural Networks</a>. Dicho comportamiento ha sido bastante estudiado y es el que logra que las redes neuronales convolucionadas capturen detalles y formas, que a su vez, las vuelven enormemente potentes en tareas de clasificacion. Es evidente que se empiezan con estructureas muy primitivas como en conv1_1 hasta llegar a formas mas  estructuradas en conv5_1.<br>\n",
    "Lo importante es entender esta capacidad de las CNN para nuestro tema de interes, es que mientras las primeras capas de la red son  mas sensibles a los colores y texturas, las ultimas capas son capaces de capturar la forma de los objetos. Dicho de otra manera, de las primeras capas capturaremos la representacion de la imagen de estilo,luego, de la imagen de contenido obtendremos la representacion de alguna de las ultimas capas, por ejemplo de <b><i>conv5_1</i></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especificamente en el articulo de  Leon A. Gatys  se usa para capturar el estilo: y para capturar el contenido :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esa manera el primer paso es tomar una red nerural entrenada y pasar a traves de ella dos imagenes, una para el contenido y otra para el estilo. Luego, capturar las respectias capas de interes para cada una."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, debemos generar una tercer imagen la cual sera el resultado(por ejemplo ver <b><i>imagen 1</i></b>) de la combinacion de las dos anteriores. En el articulo generan una imagen con ruido gaussiano. Experimentos posteriores de la tesis  demuestra que al usar la imagen de contenido como imagen de inicio da resultados mas consistentes. En los experimentos usaremos ambas.\n",
    "\n",
    "Luego, pasaremos la imagen generada por la red extrayendo tanto las capas de contenido como de estilo y calcularemos una perdida de estilo respecto a las capas obtenidad de la  imagen de estilo, y otra perdida de contenido respecto a las capas de la imagen de contenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"width: 100%;text-align:center;\">Funciones de costo</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perdida de estilo</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos una forma especial para calcular la perdida de estilo dado que el estilo esta relacionado con la correlacion que hay en una imagen enter los pixeles. La forma que sabemos como es esta correlacion es mediante una matrix gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe align=\"middle\" width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/e718uVAW3KU\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe align=\"middle\" width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/e718uVAW3KU\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perdida de contenido</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"width: 100%;text-align:center;\">Estrategia de generacion de imagen</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar, discutiremos el flujo de lo revisado hasta el momento paso por paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar pasamos la imagen de estilo y la imagen de contenido a travez de la red neuroal ya entrenada.\n",
    "Obtenemos las capas convolucionales que deseemos de cada una de ellas. Segun el articulo para la imagen de estilo obtendriamos los mapas de caracteristicas ubicados en las capas <b><i> conv1_1, conv2_1, conv3_1, conv4_1, conv5_1 </i></b>, al mismo tiempo, para la imagen de contenido obtenemos solo <b><i>conv5_2</i></b>.\n",
    "<br>\n",
    "\n",
    "Para <b><i> conv1_1, conv2_1, conv3_1, conv4_1, conv5_1, conv5_2 </i></b> de la imagen de estilo calculamos las matrices gram.\n",
    "\n",
    "Posteriormente necesitamos una imagen que nos servira de lienzo para la imagen generada. Esta imagen puede ser una imagen que generemos con ruido (puede ser una imagen generada mediante una distribusion normal) o la imagen de contenido. Los experimentos mostrados en la tesis y el articulo muestran que si se inicia con la imagen de contenido la transferencia de estilo es mas estable y fiel al contenido.\n",
    "Esta imagen generada se pasa por la red neuronal y se extrae de ella tanto las capas que se obtenieron de la imagen de estilo como la de contenido, en otras palabras, de la imagen generada se obtendra <b><i> conv1_1, conv2_1, conv3_1, conv4_1, conv5_1, conv5_2 </i></b>.\n",
    "\n",
    "Ahora, calculamos las matrices gram de la imagen generada y realizamos la perdida de estilo respecto a las matrices gram de la imagen de estilo. De forma similar, calculamos la diferente de <b><i>conv5_2</i></b> de la imagen generada respecto a la imagen de contenido.\n",
    "\n",
    "Sumamos ambos errores y a continuacion calculamos los gradiente de la imagen generada respecto al error total.\n",
    "Repetimos este proceso el numero de optimizacion que se le quieran realizar a la imagen generada. A mayor numero de iteracion se espera que la imagen generada tenga mejores resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Course_Dl",
   "language": "python",
   "name": "course_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
